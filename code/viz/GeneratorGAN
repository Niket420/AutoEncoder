digraph {
	graph [size="25.95,25.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	130545585692464 [label="
 (1, 3, 224, 224)" fillcolor=darkolivegreen1]
	130545585553024 [label=TanhBackward0]
	130545585553312 -> 130545585553024
	130545585553312 [label=ConvolutionBackward0]
	130545585553168 -> 130545585553312
	130545585553168 [label=ConstantPadNdBackward0]
	130545585553120 -> 130545585553168
	130545585553120 [label=UpsampleNearest2DBackward0]
	130545585848528 -> 130545585553120
	130545585848528 [label=CatBackward0]
	130545585848624 -> 130545585848528
	130545585848624 [label=ReluBackward0]
	130545585848768 -> 130545585848624
	130545585848768 [label=NativeBatchNormBackward0]
	130545585848816 -> 130545585848768
	130545585848816 [label=ConvolutionBackward0]
	130545585849104 -> 130545585848816
	130545585849104 [label=CatBackward0]
	130545585849248 -> 130545585849104
	130545585849248 [label=ReluBackward0]
	130545585849392 -> 130545585849248
	130545585849392 [label=NativeBatchNormBackward0]
	130545585849440 -> 130545585849392
	130545585849440 [label=ConvolutionBackward0]
	130545585849728 -> 130545585849440
	130545585849728 [label=CatBackward0]
	130545585849872 -> 130545585849728
	130545585849872 [label=ReluBackward0]
	130545585850016 -> 130545585849872
	130545585850016 [label=NativeBatchNormBackward0]
	130545585850064 -> 130545585850016
	130545585850064 [label=ConvolutionBackward0]
	130545585850352 -> 130545585850064
	130545585850352 [label=CatBackward0]
	130545585850496 -> 130545585850352
	130545585850496 [label=ReluBackward0]
	130545585850640 -> 130545585850496
	130545585850640 [label=NativeBatchNormBackward0]
	130545585850688 -> 130545585850640
	130545585850688 [label=ConvolutionBackward0]
	130545585850976 -> 130545585850688
	130545585850976 [label=AddBackward0]
	130545585851120 -> 130545585850976
	130545585851120 [label=LeakyReluBackward0]
	130545585851216 -> 130545585851120
	130545585851216 [label=ConvolutionBackward0]
	130545585850448 -> 130545585851216
	130545585850448 [label=LeakyReluBackward0]
	130545585851456 -> 130545585850448
	130545585851456 [label=NativeBatchNormBackward0]
	130545585851504 -> 130545585851456
	130545585851504 [label=ConvolutionBackward0]
	130545585849824 -> 130545585851504
	130545585849824 [label=LeakyReluBackward0]
	130545585851888 -> 130545585849824
	130545585851888 [label=NativeBatchNormBackward0]
	130545585851936 -> 130545585851888
	130545585851936 [label=ConvolutionBackward0]
	130545585849200 -> 130545585851936
	130545585849200 [label=LeakyReluBackward0]
	130545585852320 -> 130545585849200
	130545585852320 [label=NativeBatchNormBackward0]
	130545585852368 -> 130545585852320
	130545585852368 [label=ConvolutionBackward0]
	130545585848576 -> 130545585852368
	130545585848576 [label=LeakyReluBackward0]
	130545585852752 -> 130545585848576
	130545585852752 [label=ConvolutionBackward0]
	130545585852800 -> 130545585852752
	130545585687344 [label="down1.model.0.weight
 (32, 3, 4, 4)" fillcolor=lightblue]
	130545585687344 -> 130545585852800
	130545585852800 [label=AccumulateGrad]
	130545585852656 -> 130545585852368
	130545596656880 [label="down2.model.0.weight
 (128, 32, 4, 4)" fillcolor=lightblue]
	130545596656880 -> 130545585852656
	130545585852656 [label=AccumulateGrad]
	130545585852128 -> 130545585852320
	130545605864208 [label="down2.model.1.weight
 (128)" fillcolor=lightblue]
	130545605864208 -> 130545585852128
	130545585852128 [label=AccumulateGrad]
	130545585852464 -> 130545585852320
	130545600840784 [label="down2.model.1.bias
 (128)" fillcolor=lightblue]
	130545600840784 -> 130545585852464
	130545585852464 [label=AccumulateGrad]
	130545585852224 -> 130545585851936
	130545605732336 [label="down3.model.0.weight
 (256, 128, 4, 4)" fillcolor=lightblue]
	130545605732336 -> 130545585852224
	130545585852224 [label=AccumulateGrad]
	130545585851696 -> 130545585851888
	130545598721744 [label="down3.model.1.weight
 (256)" fillcolor=lightblue]
	130545598721744 -> 130545585851696
	130545585851696 [label=AccumulateGrad]
	130545585852032 -> 130545585851888
	130545594508496 [label="down3.model.1.bias
 (256)" fillcolor=lightblue]
	130545594508496 -> 130545585852032
	130545585852032 [label=AccumulateGrad]
	130545585851792 -> 130545585851504
	130545585687584 [label="down4.model.0.weight
 (256, 256, 4, 4)" fillcolor=lightblue]
	130545585687584 -> 130545585851792
	130545585851792 [label=AccumulateGrad]
	130545585851360 -> 130545585851456
	130545585687664 [label="down4.model.1.weight
 (256)" fillcolor=lightblue]
	130545585687664 -> 130545585851360
	130545585851360 [label=AccumulateGrad]
	130545585851600 -> 130545585851456
	130545585687744 [label="down4.model.1.bias
 (256)" fillcolor=lightblue]
	130545585687744 -> 130545585851600
	130545585851600 [label=AccumulateGrad]
	130545585851264 -> 130545585851216
	130545585688224 [label="down5.model.0.weight
 (256, 256, 4, 4)" fillcolor=lightblue]
	130545585688224 -> 130545585851264
	130545585851264 [label=AccumulateGrad]
	130545585850928 -> 130545585850688
	130545585688384 [label="up1.model.0.weight
 (256, 256, 4, 4)" fillcolor=lightblue]
	130545585688384 -> 130545585850928
	130545585850928 [label=AccumulateGrad]
	130545585850544 -> 130545585850640
	130545585688464 [label="up1.model.1.weight
 (256)" fillcolor=lightblue]
	130545585688464 -> 130545585850544
	130545585850544 [label=AccumulateGrad]
	130545585850784 -> 130545585850640
	130545585688544 [label="up1.model.1.bias
 (256)" fillcolor=lightblue]
	130545585688544 -> 130545585850784
	130545585850784 [label=AccumulateGrad]
	130545585850448 -> 130545585850352
	130545585850304 -> 130545585850064
	130545585689024 [label="up2.model.0.weight
 (512, 256, 4, 4)" fillcolor=lightblue]
	130545585689024 -> 130545585850304
	130545585850304 [label=AccumulateGrad]
	130545585849920 -> 130545585850016
	130545585689104 [label="up2.model.1.weight
 (256)" fillcolor=lightblue]
	130545585689104 -> 130545585849920
	130545585849920 [label=AccumulateGrad]
	130545585850160 -> 130545585850016
	130545585689184 [label="up2.model.1.bias
 (256)" fillcolor=lightblue]
	130545585689184 -> 130545585850160
	130545585850160 [label=AccumulateGrad]
	130545585849824 -> 130545585849728
	130545585849680 -> 130545585849440
	130545585689584 [label="up3.model.0.weight
 (512, 128, 4, 4)" fillcolor=lightblue]
	130545585689584 -> 130545585849680
	130545585849680 [label=AccumulateGrad]
	130545585849296 -> 130545585849392
	130545585689664 [label="up3.model.1.weight
 (128)" fillcolor=lightblue]
	130545585689664 -> 130545585849296
	130545585849296 [label=AccumulateGrad]
	130545585849536 -> 130545585849392
	130545585689744 [label="up3.model.1.bias
 (128)" fillcolor=lightblue]
	130545585689744 -> 130545585849536
	130545585849536 [label=AccumulateGrad]
	130545585849200 -> 130545585849104
	130545585849056 -> 130545585848816
	130545585690144 [label="up4.model.0.weight
 (256, 32, 4, 4)" fillcolor=lightblue]
	130545585690144 -> 130545585849056
	130545585849056 [label=AccumulateGrad]
	130545585848672 -> 130545585848768
	130545585690224 [label="up4.model.1.weight
 (32)" fillcolor=lightblue]
	130545585690224 -> 130545585848672
	130545585848672 [label=AccumulateGrad]
	130545585848912 -> 130545585848768
	130545585690304 [label="up4.model.1.bias
 (32)" fillcolor=lightblue]
	130545585690304 -> 130545585848912
	130545585848912 [label=AccumulateGrad]
	130545585848576 -> 130545585848528
	130545585553360 -> 130545585553312
	130545585690704 [label="final.2.weight
 (3, 64, 4, 4)" fillcolor=lightblue]
	130545585690704 -> 130545585553360
	130545585553360 [label=AccumulateGrad]
	130545585553264 -> 130545585553312
	130545585690784 [label="final.2.bias
 (3)" fillcolor=lightblue]
	130545585690784 -> 130545585553264
	130545585553264 [label=AccumulateGrad]
	130545585553024 -> 130545585692464
}
